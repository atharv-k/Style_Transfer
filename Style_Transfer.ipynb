{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LPntNcVJQdwO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torchvision\n",
        "import random\n",
        "import IPython.display as display\n",
        "from torchsummary import summary\n",
        "#from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "import torchvision.utils as utils\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW0duWuNUZmE",
        "outputId": "8a2d3655-261b-4b53-e2ad-128d714008c1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "landscape_photo_dir = '/content/drive/MyDrive/Project Data/gan-getting-started/photo_jpg'\n",
        "monet_photo_dir = '/content/drive/MyDrive/Project Data/gan-getting-started/monet_jpg'\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "learning_rate = 0.001\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "Vim0NbZixLXn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def add_noise(image, noise=0.3):\n",
        "#  img = transforms.ToTensor()(image)\n",
        "#  img = img + torch.rand_like(img)*noise\n",
        "#  img = torch.clip(img,0,1)\n",
        "#  img = transforms.ToPILImage()(img)\n",
        "#  return img\n",
        "\n",
        "#def image_transformations(image):\n",
        "#  yield transforms.RandomRotation(25,interpolation=Image.BILINEAR,fill=[0.485*255, 0.456*255, 0.406*255])(image)\n",
        "#  yield transforms.RandomRotation(45,interpolation=Image.BILINEAR,fill=[0.485*255, 0.456*255, 0.406*255])(image)\n",
        "#  yield transforms.RandomRotation(85,interpolation=Image.BILINEAR,fill=[0.485*255, 0.456*255, 0.406*255])(image)\n",
        "#  yield transforms.RandomRotation(65,interpolation=Image.BILINEAR,fill=[0.485*255, 0.456*255, 0.406*255])(image)\n",
        "#  yield add_noise(image,0.25)\n",
        "#  yield add_noise(image)\n",
        "#  yield add_noise(image,0.45)\n",
        "#  yield add_noise(image,0.6)\n",
        "#  yield transforms.RandomHorizontalFlip(1)(image)\n",
        "#  yield  transforms.RandomVerticalFlip(1)(image)\n",
        "\n",
        "\n",
        "#def dataset_augmentation(root_folderpath):\n",
        "#  files = os.listdir(root_folderpath)\n",
        "#  for img_path in files:\n",
        "#    img = Image.open(os.path.join(root_folderpath,img_path))"
      ],
      "metadata": {
        "id": "rb-0eFNjT6vk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "\n",
        "  def __init__(self,root,transform):\n",
        "    self.root = root\n",
        "    self.files = os.listdir(root)\n",
        "    self.transforms = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_path = os.path.join(self.root,self.files[index])\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img = self.transforms(img)\n",
        "    return img"
      ],
      "metadata": {
        "id": "etBU3xiFVi3w"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CombineDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.Image_A = ImageDataset()\n",
        "    self.Image_B = ImageDataset()\n",
        "\n",
        "  def __len__(self):\n",
        "    return min(len(self.Image_A),len(self.Image_B))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.Image_A[index], self.Image_B[index]"
      ],
      "metadata": {
        "id": "qbvxtF0QImrE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init():\n",
        "  \"To initialise the weights using different initialisation techniques\"\n",
        "  pass\n",
        "\n",
        "def set_model():\n",
        "  \"To create an model of given specifications\"\n",
        "  pass"
      ],
      "metadata": {
        "id": "MvXd9PSRUpSA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self,in_ch,final_out_ch,filters):\n",
        "    super().__init__()\n",
        "\n",
        "    self.e1 = self.encoder_block(in_ch,filters,outermost=True)\n",
        "    self.e2 = self.encoder_block(filters,filters*2)\n",
        "    self.e3 = self.encoder_block(filters*2,filters*4)\n",
        "    self.e4 = self.encoder_block(filters*4,filters*8)\n",
        "    self.e5 = self.encoder_block(filters*8,filters*8)\n",
        "    self.e6 = self.encoder_block(filters*8,filters*8)\n",
        "    self.e7 = self.encoder_block(filters*8,filters*8)\n",
        "    self.e8 = self.encoder_block(filters*8,filters*8,innermost=True)\n",
        "\n",
        "    self.d1 = self.decoder_block(filters*8,filters*8)\n",
        "    self.d2 = self.decoder_block(2*filters*8,filters*8)\n",
        "    self.d3 = self.decoder_block(2*filters*8,filters*8)\n",
        "    self.d4 = self.decoder_block(2*filters*8,filters*8)\n",
        "    self.d5 = self.decoder_block(2*filters*8,filters*4)\n",
        "    self.d6 = self.decoder_block(2*filters*4,filters*2)\n",
        "    self.d7 = self.decoder_block(2*filters*2,filters)\n",
        "    self.d8 = self.decoder_block(2*filters,final_out_ch,outermost=True)\n",
        "\n",
        "  def encoder_block(self,in_channel,out_channel,innermost=False,outermost=False):\n",
        "    conv = nn.Conv2d(in_channels=in_channel,out_channels=out_channel,kernel_size=4,stride=2,padding=1)\n",
        "    activ = nn.LeakyReLU(0.2,True)\n",
        "    norm = nn.BatchNorm2d(out_channel)\n",
        "    if outermost:\n",
        "      model = [conv]\n",
        "    elif innermost:\n",
        "      model = [activ, conv]\n",
        "    else:\n",
        "      model = [activ, conv, norm]\n",
        "    return nn.Sequential(*model)\n",
        "\n",
        "  def decoder_block(self,in_channel,out_channel,outermost=False):\n",
        "    convtrans = nn.ConvTranspose2d(in_channels=in_channel,out_channels=out_channel,kernel_size=4,stride=2,padding=1)\n",
        "    activ = nn.ReLU(True)\n",
        "    norm = nn.Tanh() if outermost else nn.BatchNorm2d(out_channel)\n",
        "    model = [activ, convtrans, norm]\n",
        "    return nn.Sequential(*model)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    e1 = self.e1(inputs)\n",
        "    e2 = self.e2(e1)\n",
        "    e3 = self.e3(e2)\n",
        "    e4 = self.e4(e3)\n",
        "    e5 = self.e5(e4)\n",
        "    e6 = self.e6(e5)\n",
        "    e7 = self.e7(e6)\n",
        "    e8 = self.e8(e7)\n",
        "    d1 = self.d1(e8)\n",
        "    d1 = torch.cat([e7,d1],1)\n",
        "    d2 = self.d2(d1)\n",
        "    d2 = torch.cat([e6,d2],1)\n",
        "    d3 = self.d3(d2)\n",
        "    d3 = torch.cat([e5,d3],1)\n",
        "    d4 = self.d4(d3)\n",
        "    d4 = torch.cat([e4,d4],1)\n",
        "    d5 = self.d5(d4)\n",
        "    d5 = torch.cat([e3,d5],1)\n",
        "    d6 = self.d6(d5)\n",
        "    d6 = torch.cat([e2,d6],1)\n",
        "    d7 = self.d7(d6)\n",
        "    d7 = torch.cat([e1,d7],1)\n",
        "    d8 = self.d8(d7)\n",
        "    return d8"
      ],
      "metadata": {
        "id": "eegAiVgRqGo3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "gen = Generator(3,3,64).to(device)\n",
        "summary(gen, (3,256,256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMKM9NnM2-2_",
        "outputId": "7558293a-fdc6-4959-d890-b5536e156bca"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           3,136\n",
            "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3          [-1, 128, 64, 64]         131,200\n",
            "       BatchNorm2d-4          [-1, 128, 64, 64]             256\n",
            "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
            "            Conv2d-6          [-1, 256, 32, 32]         524,544\n",
            "       BatchNorm2d-7          [-1, 256, 32, 32]             512\n",
            "         LeakyReLU-8          [-1, 256, 32, 32]               0\n",
            "            Conv2d-9          [-1, 512, 16, 16]       2,097,664\n",
            "      BatchNorm2d-10          [-1, 512, 16, 16]           1,024\n",
            "        LeakyReLU-11          [-1, 512, 16, 16]               0\n",
            "           Conv2d-12            [-1, 512, 8, 8]       4,194,816\n",
            "      BatchNorm2d-13            [-1, 512, 8, 8]           1,024\n",
            "        LeakyReLU-14            [-1, 512, 8, 8]               0\n",
            "           Conv2d-15            [-1, 512, 4, 4]       4,194,816\n",
            "      BatchNorm2d-16            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-17            [-1, 512, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 2, 2]       4,194,816\n",
            "      BatchNorm2d-19            [-1, 512, 2, 2]           1,024\n",
            "        LeakyReLU-20            [-1, 512, 2, 2]               0\n",
            "           Conv2d-21            [-1, 512, 1, 1]       4,194,816\n",
            "             ReLU-22            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-23            [-1, 512, 2, 2]       4,194,816\n",
            "      BatchNorm2d-24            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-25           [-1, 1024, 2, 2]               0\n",
            "  ConvTranspose2d-26            [-1, 512, 4, 4]       8,389,120\n",
            "      BatchNorm2d-27            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-28           [-1, 1024, 4, 4]               0\n",
            "  ConvTranspose2d-29            [-1, 512, 8, 8]       8,389,120\n",
            "      BatchNorm2d-30            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-31           [-1, 1024, 8, 8]               0\n",
            "  ConvTranspose2d-32          [-1, 512, 16, 16]       8,389,120\n",
            "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-34         [-1, 1024, 16, 16]               0\n",
            "  ConvTranspose2d-35          [-1, 256, 32, 32]       4,194,560\n",
            "      BatchNorm2d-36          [-1, 256, 32, 32]             512\n",
            "             ReLU-37          [-1, 512, 32, 32]               0\n",
            "  ConvTranspose2d-38          [-1, 128, 64, 64]       1,048,704\n",
            "      BatchNorm2d-39          [-1, 128, 64, 64]             256\n",
            "             ReLU-40          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-41         [-1, 64, 128, 128]         262,208\n",
            "      BatchNorm2d-42         [-1, 64, 128, 128]             128\n",
            "             ReLU-43        [-1, 128, 128, 128]               0\n",
            "  ConvTranspose2d-44          [-1, 3, 256, 256]           6,147\n",
            "             Tanh-45          [-1, 3, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 54,419,459\n",
            "Trainable params: 54,419,459\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 102.30\n",
            "Params size (MB): 207.59\n",
            "Estimated Total Size (MB): 310.65\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channel,filter):\n",
        "    super().__init__()\n",
        "    kernel_size = 4\n",
        "    stride = 2\n",
        "    padding = 1\n",
        "    model = [nn.Conv2d(in_channels=in_channel,out_channels=filter,kernel_size=kernel_size,stride=stride,padding=padding),nn.LeakyReLU(0.2,True)]\n",
        "    for i in range(3):\n",
        "      if i == 2:\n",
        "        stride = 1\n",
        "      in_scale = 2**i\n",
        "      out_scale = 2**(i+1)\n",
        "      model += [\n",
        "          nn.Conv2d(filter*in_scale,filter*out_scale,kernel_size,stride,padding),\n",
        "          nn.BatchNorm2d(filter*out_scale),\n",
        "          nn.LeakyReLU(0.2,True)\n",
        "      ]\n",
        "    model += [nn.Conv2d(filter*8,1,kernel_size,1,padding)]\n",
        "    self.model = nn.Sequential(*model)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    return self.model(inputs)"
      ],
      "metadata": {
        "id": "iuG4GN804Oe7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "dis = Discriminator(3,64).to(device)\n",
        "summary(dis, (3,256,256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h23LTb4DbI9Y",
        "outputId": "c8a4e7d0-699e-4318-d4ac-e0199058f91f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           3,136\n",
            "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3          [-1, 128, 64, 64]         131,200\n",
            "       BatchNorm2d-4          [-1, 128, 64, 64]             256\n",
            "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
            "            Conv2d-6          [-1, 256, 32, 32]         524,544\n",
            "       BatchNorm2d-7          [-1, 256, 32, 32]             512\n",
            "         LeakyReLU-8          [-1, 256, 32, 32]               0\n",
            "            Conv2d-9          [-1, 512, 31, 31]       2,097,664\n",
            "      BatchNorm2d-10          [-1, 512, 31, 31]           1,024\n",
            "        LeakyReLU-11          [-1, 512, 31, 31]               0\n",
            "           Conv2d-12            [-1, 1, 30, 30]           8,193\n",
            "================================================================\n",
            "Total params: 2,766,529\n",
            "Trainable params: 2,766,529\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 45.27\n",
            "Params size (MB): 10.55\n",
            "Estimated Total Size (MB): 56.57\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGanLoss:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.classification_loss  = nn.BCEWithLogitsLoss()\n",
        "    self.reco_loss = nn.L1Loss()\n",
        "\n",
        "  def discriminator_loss(self,logits,isFake=False):\n",
        "    target_labels = None\n",
        "    if isFake:\n",
        "      target_labels = torch.zeros_like(logits,device=device)\n",
        "    else:\n",
        "      target_labels = torch.ones_like(logits,device=device)\n",
        "    loss = self.classification_loss(logits,target_labels)\n",
        "    return loss\n",
        "\n",
        "  def generator_loss(self,logits):\n",
        "    target_labels = torch.ones_like(logits,device=device)\n",
        "    loss = self.classification_loss(logits,target_labels)\n",
        "    return loss\n",
        "\n",
        "  def reconstruction_loss(self,logits,org):\n",
        "    loss = self.recon_loss(logits,org)\n",
        "    return loss\n",
        "\n",
        "  def __call__(self,real_1,rec_1,real_logits_2,fake_logits_2):\n",
        "    gen_loss = self.generator_loss(fake_logits_2)\n",
        "    disc_loss_real = self.discriminator_loss(real_logits_2)\n",
        "    disc_loss_fake = self.discriminator_loss(fake_logits_2,isFake=True)\n",
        "    rec_loss = self.reconstruction_loss(rec_1,real_1)\n",
        "    loss = gen_loss + disc_loss_real + disc_loss_fake + rec_loss\n",
        "    return loss"
      ],
      "metadata": {
        "id": "XBUEyC4cN1eG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGAN:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.Generator_A2B = None\n",
        "    self.Generator_B2A = None\n",
        "    self.Discriminator_A = None\n",
        "    self.Discriminator_B = None\n",
        "    self.CGLoss = CycleGanLoss()\n",
        "    self.mode_A2B = True\n",
        "    self.Gen_A2B_optimizer = torch.optim.Adagrad(\n",
        "        self.Generator_A2B.parameters(), lr=learning_rate)\n",
        "    self.Gen_B2A_optimizer = torch.optim.Adagrad(\n",
        "        self.Generator_B2A.parameters(), lr=learning_rate)\n",
        "    self.Disc_A_optimizer = torch.optim.Adagrad(\n",
        "        self.Discriminator_A.parameters(), lr=learning_rate)\n",
        "    self.Disc_B_optimizer = torch.optim.Adagrad(\n",
        "        self.Discriminator_B.parameters(), lr=learning_rate)\n",
        "\n",
        "  def __call__(self,*dataset,Train_mode=False):\n",
        "    if Train_mode:\n",
        "      domain_A, domain_B = dataset\n",
        "      fake_B = self.Generator_A2B(domain_A)\n",
        "      rec_A = self.Generator_B2A(fake_B)\n",
        "      fake_A = self.Generator_B2A(domain_B)\n",
        "      rec_B = self.Generator_A2B(fake_A)\n",
        "      return fake_B,rec_A,fake_A,rec_B\n",
        "    else:\n",
        "      if self.mode_A2B:\n",
        "        domain_A = dataset[0]\n",
        "        fake_B = self.Generator_A2B(domain_A)\n",
        "        return fake_B\n",
        "      else:\n",
        "        domain_B = dataset[0]\n",
        "        fake_A = self.Generator_B2A(domain_B)\n",
        "        return fake_A\n",
        "\n",
        "  def train(self,epochs,dataloader):\n",
        "    for e in epochs:\n",
        "      for images_A, images_B in dataloader:\n",
        "        self.Gen_A2B_optimizer.zero_grad()\n",
        "        self.Gen_B2A_optimizer.zero_grad()\n",
        "        self.Disc_A_optimizer.zero_grad()\n",
        "        self.Disc_B_optimizer.zero_grad()\n",
        "        fake_B, rec_A, fake_A, rec_B = self(images_A,images_B,Train_mode=True)\n",
        "        fake_logits_A = self.Discriminator_A(fake_A)\n",
        "        real_logits_A = self.Discriminator_A(images_A)\n",
        "        fake_logits_B = self.Discriminator_B(fake_B)\n",
        "        real_logits_B = self.Discriminator_B(images_B)\n",
        "        A2B_loss = self.CGLoss(images_A,rec_A,real_logits_B,fake_logits_B)\n",
        "        B2A_loss = self.CGLoss(images_B,rec_B,real_logits_A,fake_logits_A)\n",
        "        A2B_loss.backward()\n",
        "        B2A_loss.backward()\n",
        "        self.Gen_A2B_optimizer.step()\n",
        "        self.Gen_B2A_optimizer.step()\n",
        "        self.Disc_A_optimizer.step()\n",
        "        self.Disc_B_optimizer.step()\n",
        "\n",
        "  def eval(self):\n",
        "    pass"
      ],
      "metadata": {
        "id": "QRSa6iX2guM_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3P0UiX6nCRk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}